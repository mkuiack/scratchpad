{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xa"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afhome/kuiack/newtrap/local/lib/python2.7/site-packages/pyfits/__init__.py:22: PyFITSDeprecationWarning: PyFITS is deprecated, please use astropy.io.fits\n",
      "  PyFITSDeprecationWarning)  # noqa\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import tkp.db\n",
    "import tkp.config\n",
    "import logging\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import numbers\n",
    "import math\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import sem\n",
    "from scipy import linspace\n",
    "from scipy import pi,sqrt,exp\n",
    "from scipy.special import erf\n",
    "\n",
    "import pylab\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "plt.rcParams['font.size']=16\n",
    "plt.rcParams['axes.labelsize']='large'\n",
    "plt.rcParams['axes.titlesize']='large'\n",
    "pylab.rcParams['legend.loc'] = 'best'\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsf(num, n=1):\n",
    "    \"\"\"n-Significant Figures\"\"\"\n",
    "    numstr = (\"{0:.%ie}\" % (n-1)).format(num)\n",
    "    return float(numstr)\n",
    "\n",
    "def num_err(num, err, n=1):\n",
    "    '''Return number rounded based on error'''\n",
    "    return np.around(num,int(-(np.floor(np.log10(nsf(err,n=n)))))), nsf(err,n=n)\n",
    "\n",
    "def clip(data, sigma=3):\n",
    "    \"\"\"Remove all values above a threshold from the array.\n",
    "    Uses iterative clipping at sigma value until nothing more is getting clipped.\n",
    "    Args:\n",
    "        data: a numpy array\n",
    "    \"\"\"\n",
    "    data = data[np.isfinite(data)]\n",
    "    raveled = data.ravel()\n",
    "    median = np.median(raveled)\n",
    "    std = np.nanstd(raveled)\n",
    "    newdata = raveled[np.abs(raveled-median) <= sigma*std]\n",
    "    if len(newdata) and len(newdata) != len(raveled):\n",
    "        return clip(newdata, sigma)\n",
    "    else:\n",
    "        return newdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_trans(dbname, dataset_id, engine, host, port, user, pword):\n",
    "    tkp.db.Database(\n",
    "        database=dbname, user=user, password=pword,\n",
    "        engine=engine, host=host, port=port\n",
    "    )\n",
    "\n",
    "    # find all the new, candidate transient, sources detected by the pipeline\n",
    "    transients_query = \"\"\"\n",
    "    SELECT  tr.runcat\n",
    "           ,tr.newsource_type\n",
    "           ,im.rms_min\n",
    "           ,im.rms_max\n",
    "           ,im.detection_thresh\n",
    "           ,ex.f_int\n",
    "    FROM newsource tr\n",
    "         ,image im\n",
    "         ,extractedsource ex\n",
    "    WHERE tr.previous_limits_image = im.id\n",
    "      AND tr.trigger_xtrsrc = ex.id\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor = tkp.db.execute(transients_query, (dataset_id,))\n",
    "    transients = tkp.db.generic.get_db_rows_as_dicts(cursor)\n",
    "    print \"Found\", len(transients), \"new sources\"\n",
    "    return transients\n",
    "\n",
    "def dump_sources(dbname, dataset_id, engine, host, port, user, pword):\n",
    "    tkp.db.Database(\n",
    "        database=dbname, user=user, password=pword,\n",
    "        engine=engine, host=host, port=port\n",
    "    )\n",
    "    # extract the properties and variability parameters for all the running catalogue sources in the dataset\n",
    "    sources_query = \"\"\"\\\n",
    "    SELECT  im.taustart_ts\n",
    "            ,im.tau_time\n",
    "            ,ex.f_int\n",
    "            ,ex.f_int_err\n",
    "            ,ex.f_peak\n",
    "            ,ex.f_peak_err\n",
    "            ,ax.xtrsrc\n",
    "            ,ex.extract_type\n",
    "            ,ex.det_sigma\n",
    "            ,ax.runcat as runcatid\n",
    "            ,ex.ra\n",
    "            ,ex.decl\n",
    "            ,ex.ra_err\n",
    "            ,ex.decl_err\n",
    "            ,im.band\n",
    "            ,im.rms_min\n",
    "            ,im.rms_max\n",
    "            ,ax.v_int\n",
    "            ,ax.eta_int\n",
    "            ,ax.f_datapoints\n",
    "            ,im.freq_eff\n",
    "            ,im.url\n",
    "    FROM extractedsource ex\n",
    "         ,assocxtrsource ax\n",
    "         ,image im\n",
    "         ,runningcatalog rc\n",
    "    WHERE ax.runcat = rc.id\n",
    "      AND ax.xtrsrc = ex.id\n",
    "      and ex.image = im.id\n",
    "      AND rc.dataset = %s\n",
    "      ORDER BY rc.id\n",
    "    \"\"\"\n",
    "    cursor = tkp.db.execute(sources_query, (dataset_id,))\n",
    "    sources = tkp.db.generic.get_db_rows_as_dicts(cursor)\n",
    "\n",
    "    print \"Found\", len(sources), \"source datapoints\"\n",
    "\n",
    "    return sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distSquared(p0, p1):\n",
    "    distance  = np.sqrt((p0[0] - p1[0,:])**2 + (p0[1] - p1[1,:])**2)\n",
    "    if np.min(distance) < 3.0:\n",
    "        return np.where(distance == np.min(distance))[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def pol2cart(rho, phi):\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_source(full_data, run_id):\n",
    "    source_df = full_data[(full_data.runcatid == run_id)]\n",
    "    \n",
    "#     source_df = source_df.groupby('taustart_ts', as_index=False)\n",
    "    source_df.set_index(source_df.taustart_ts, inplace=True)\n",
    "    return source_df.sort_index()\n",
    "\n",
    "\n",
    "def plot_lightcurve(full_data, run_id, ion_sub=False, roll_len = 1*60, roll_type = 'triang', stdout=True):\n",
    "\n",
    "    source_df = full_data[(full_data.runcatid == run_id)]\n",
    "    if stdout:\n",
    "        print source_df.wm_ra.iloc[0], source_df.wm_decl.iloc[0]\n",
    "\n",
    "    pd.to_datetime(source_df.taustart_ts)\n",
    "    source_df = source_df.groupby('taustart_ts', as_index=False).mean()\n",
    "    source_df.set_index(source_df.taustart_ts, inplace=True)\n",
    "\n",
    "    if ion_sub:\n",
    "        rolling = source_df.f_int.rolling(roll_len, win_type=roll_type)\n",
    "        source_df.f_int = source_df.f_int-rolling.mean()\n",
    "\n",
    "\n",
    "    plt.rcParams['font.size']=16\n",
    "    plt.rcParams['axes.labelsize']='large'\n",
    "    plt.rcParams['axes.titlesize']='large'\n",
    "    pylab.rcParams['legend.loc'] = 'best'\n",
    "\n",
    "    ylim = [np.nanmean(source_df.f_int)-6.0*np.nanstd(source_df.f_int),\n",
    "            np.nanmean(source_df.f_int)+10.0*np.nanstd(source_df.f_int)]\n",
    "\n",
    "\n",
    "\n",
    "    myFmt = mdates.DateFormatter('%H:%M')\n",
    "    source_df[\"taustart_ts\"] = pd.to_datetime(source_df[\"taustart_ts\"])\n",
    "    obs_dates = np.unique([100*x.month+x.day for x in source_df[\"taustart_ts\"]])\n",
    "\n",
    "    n_hours = np.array([]) \n",
    "    for i in obs_dates:\n",
    "        index = (100*pd.DatetimeIndex(source_df[\"taustart_ts\"]).month+pd.DatetimeIndex(source_df[\"taustart_ts\"]).day == i)# & (source_df.extract_type == 0)\n",
    "        n_hours = np.append(n_hours, len(np.unique(pd.DatetimeIndex(source_df[\"taustart_ts\"][index]).hour)))\n",
    "    hour_ratio = [i/n_hours.sum() for i in n_hours ]\n",
    "    gs_ratio = np.append((hour_ratio)/min(hour_ratio),1)\n",
    "\n",
    "    gs = gridspec.GridSpec(1, len(obs_dates)+1, width_ratios=gs_ratio) \n",
    "\n",
    "    figcount = 0\n",
    "    figure = plt.figure(figsize=(4*len(obs_dates),6))\n",
    "\n",
    "    for i in obs_dates:\n",
    "        index = (100*pd.DatetimeIndex(source_df[\"taustart_ts\"]).month+pd.DatetimeIndex(source_df[\"taustart_ts\"]).day == i)# & (source_df.extract_type == 0)\n",
    "        ax = plt.subplot(gs[figcount])\n",
    "        ax.locator_params(nticks=6)\n",
    "        ax.errorbar(source_df[\"taustart_ts\"].values[index],\n",
    "                    source_df[\"f_int\"].values[index],\n",
    "                    yerr=source_df[\"f_int_err\"].values[index],\n",
    "                    fmt=\".\",c=\"#1f77b4\",ecolor=\"#ff7f0e\")\n",
    "\n",
    "        if figcount > 0:\n",
    "            ax.set_yticks([])\n",
    "        if figcount ==0:\n",
    "            plt.ylabel(\"Flux [Jy]\")\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "        if stdout:\n",
    "            print source_df[\"taustart_ts\"].values[index][0]\n",
    "        plt.annotate(\"{}-{}\".format(pd.DatetimeIndex(source_df[\"taustart_ts\"].values[index]).day[0],\n",
    "                                    pd.DatetimeIndex(source_df[\"taustart_ts\"].values[index]).month[0]),\n",
    "                                    xy=(0.95,0.95), xycoords='axes fraction',\n",
    "                                    horizontalalignment='right', verticalalignment='top',fontsize=16)\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.xaxis.set_major_formatter(myFmt)\n",
    "        figcount+=1\n",
    "\n",
    "    hist_index = np.isfinite(source_df[\"f_int\"]) #& (source_df.extract_type == 0)\n",
    "    plt.subplot(gs[figcount])\n",
    "    (mu, sigma) = norm.fit(source_df[\"f_int\"].iloc[hist_index].values)\n",
    "    n, bins, patches   =  plt.hist(source_df[\"f_int\"].values[hist_index],\n",
    "                                   bins=100,normed=1, orientation='horizontal',facecolor=\"#1f77b4\")\n",
    "    y = mlab.normpdf( bins, mu, sigma)\n",
    "    if stdout:\n",
    "        print \"Gaus fit: mu {}, sigma {}\".format(round(mu,3),round(sigma,3))\n",
    "    \n",
    "    l = plt.plot(y,bins,'r--', linewidth=2)\n",
    "    # plt.title(\"Source: N = {}\".format(len(source_df[\"f_int\"].values[np.isfinite(source_df[\"f_int\"])])))\n",
    "    plt.annotate(\"Total N:\\n{}\".format(len(source_df[\"f_int\"].values[hist_index])),\n",
    "                                xy=(0.95,0.95), xycoords='axes fraction',\n",
    "                                horizontalalignment='right', verticalalignment='top',fontsize=16)\n",
    "    # plt.ylabel(\"Normalized N\")\n",
    "    plt.yticks([])\n",
    "    plt.ylim(ylim)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    return figure\n",
    "#     plt.show()\n",
    "# fig.text(0.5, 0.04, 'date', ha='center')\n",
    "# plt.tight_layout()\n",
    "# print(source_df[\"wm_ra\"].values[0],source_df[\"wm_decl\"].values[1])\n",
    "# plt.savefig(\"{}_multiday_lightcurve.png\".format(key))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = 'postgresql'\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "user = 'mkuiack'\n",
    "password = 'Morecomplicatedpass1234'\n",
    "# database = 'raw_16SB'\n",
    "# database = 'flux_16SB'\n",
    "# database = 'fluxcal_db'\n",
    "\n",
    "# databases = ['higher_201702250130','lower_201702250130']\n",
    "query_loglevel = logging.WARNING  # Set to INFO to see queries, otherwise WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AARTFAAC survey databases:\n",
    "\n",
    "# survey_stats = pd.DataFrame(\n",
    "#     [\n",
    "#     [\"_201608311510\", 1, 9229,  200, 53], # 9718 MB \n",
    "#     [\"_201609051647\", 1, 10726, 597, 17], # 11 GB \n",
    "#     [\"_201609070340\", 1, 17933, 76,  6],  # 14 GB \n",
    "#     [\"_201611120632\", 1, 28203, 310,  39],# 22 GB  \n",
    "#     [\"_201611132000\", 1, 5078, 302,  15], # 4155 MB \n",
    "#     [\"_201611140501\", 1, 13977, 370,  16],# 6170 MB \n",
    "#     [\"_201702241630\", 1, 6488,  43,  2],  # 1734 MB \n",
    "#     [\"_201702250130\", 2, 13073, 68,  1],  # 8713 MB \n",
    "#     [\"_201702250800\", 1, 21426, 0,  0],   # 23 GB \n",
    "#     [\"_201702251405\", 1, 14860, 901,  47],  # 12 GB  , delete 2018 data \n",
    "#     [\"_201702260116\", 1, 10669, 0,  0], # 6463 MB  264.31s\n",
    "#     [\"_201702260800\", 1, 21434, 239, 11], # 19 GB  \n",
    "#     [\"_201702261405\", 1, 18436, 621,  35], # 9641 MB   491. s\n",
    "#     [\"_201702270350\", 1, 4400,  67,  2],   # 975 MB \n",
    "#     [\"_201702280900\", 1, 3512,  23,  0],   # 782 MB\n",
    "#     [\"_201809230412\", 1, 17147,  676,  47],   # 12 GB\n",
    "#     [\"_201809280900\", 1, 0,  0,  0]   # 35 GB\n",
    "# #     [\"_201809281701\", 1, 0,  0,  0],   # \n",
    "# #     [\"_201809290600\", 1, 0,  0,  0]   # \n",
    "#     ],\n",
    "#     columns=[\"obs\",\"dataset\",\"timestamp\",\"candidate\",\"pass\"])\n",
    "\n",
    "\n",
    "survey_stats = pd.read_csv(\"/home/kuiack/survey_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tkp.db.database:Database config: postgresql://mkuiack@localhost:5432/ASf_20190129\n",
      "INFO:tkp.db.database:connecting to database...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database name:  ASf_20190129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tkp.db.database:Not configuring pre-configured database\n"
     ]
    }
   ],
   "source": [
    "dbname = \"ASf_20190126\"\n",
    "\n",
    "ObsDir = \"/data/AS\"+dbname+\"_Candidates/\"\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "if not os.path.exists(ObsDir):\n",
    "    os.makedirs(ObsDir)\n",
    "\n",
    "dataset = survey_stats[survey_stats.obs == dbname].dataset.values[0]\n",
    "\n",
    "\n",
    "print \"database name: \",  dbname\n",
    "logging.getLogger('sqlalchemy.engine').setLevel(query_loglevel)\n",
    "\n",
    "db = tkp.db.Database(engine=engine, host=host, port=port,\n",
    "                     user=user, password=password, database=dbname)\n",
    "\n",
    "db.connect()\n",
    "session = db.Session()\n",
    "sources = dump_sources(dbname, dataset, engine, host, port, user, password)\n",
    "print len(sources)\n",
    "data = pd.DataFrame(sources)\n",
    "\n",
    "del sources\n",
    "\n",
    "data.taustart_ts = pd.to_datetime(data.taustart_ts)\n",
    "\n",
    "# Remove bad source fits \n",
    "data = data.drop(data.index[np.abs(data.f_int) > 10e6])\n",
    "# No observations are greater than 24 hours \n",
    "data = data[data.taustart_ts.diff() < datetime.timedelta(seconds=24*3600)]\n",
    "\n",
    "\n",
    "try:\n",
    "    data[\"round_times\"] = [datetime.datetime.strptime(os.path.basename(x)[:19], \n",
    "                                                      \"%Y-%m-%dT%H:%M:%S\") for x in data.url.values]\n",
    "except ValueError:\n",
    "    data[\"round_times\"] = [datetime.datetime.strptime(os.path.basename(x)[:14], \n",
    "                                                      \"%Y%m%d%H%M%S\") for x in data.url.values]\n",
    "\n",
    "survey_stats.set_value(survey_stats.obs == dbname,\"timestamp\", len(np.unique(data.round_times)))\n",
    "survey_stats.to_csv(\"survey_stats.csv\", index=False)\n",
    "\n",
    "db._configured = False\n",
    "del db, session\n",
    "\n",
    "print time.time() - t1, \"seconds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_detections = 0 \n",
    "\n",
    "reduced = pd.DataFrame([])\n",
    "\n",
    "t1 = time.time()\n",
    "for _id in np.unique(data.runcatid):\n",
    "    if len(data[(data.runcatid == _id) & \\\n",
    "                (data.band == 23) & \\\n",
    "                (data.extract_type == 0)].set_index(\"round_times\").index.\\\n",
    "           intersection(data[(data.runcatid == _id) & \\\n",
    "                             (data.band == 24) & \\\n",
    "                             (data.extract_type == 0)].set_index(\"round_times\").index )) > N_detections \\\n",
    "    and (np.max(data[(data.runcatid == _id )].det_sigma) > 8 ):\n",
    "\n",
    "        if len(reduced) == 0:\n",
    "            reduced = pd.DataFrame(data[(data.runcatid == _id)])\n",
    "        else:\n",
    "            reduced = pd.concat([reduced,data[(data.runcatid == _id)]])\n",
    "\n",
    "print time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = reduced.groupby(\"runcatid\").median()\n",
    "base[\"taustart_ts\"] = reduced.groupby(\"runcatid\").first().taustart_ts\n",
    "base[\"timestep\"] = [x.timestamp() for x in base.taustart_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlssr = pd.read_csv(\"/home/kuiack/VLSSr.tsv\", comment=\"#\", delimiter=\"\\t\")\n",
    "tgss = pd.read_csv(\"/home/kuiack/TGSSADR1_7sigma_catalog.tsv\", delimiter=\"\\t\")\n",
    "aart = pd.read_csv(\"/home/kuiack/AARTFAAC_catalogue.csv\")\n",
    "ateam = {\"ra\":np.array([82.88,299.43,350.28,187.07]),\n",
    "         \"decl\":np.array([21.98,40.59,58.54,12.66])}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aart_coord = SkyCoord(aart.ra.values*u.deg, aart.decl.values*u.deg, frame='fk5')\n",
    "ateam_coord = SkyCoord(ateam[\"ra\"]*u.deg, ateam[\"decl\"]*u.deg, frame='fk5')\n",
    "\n",
    "filtered = pd.DataFrame([], columns=base.keys())\n",
    "AART_catsource = pd.DataFrame([], columns=base.keys())\n",
    "\n",
    "\n",
    "for i in base.index:\n",
    "    try:\n",
    "        c1 = SkyCoord(base.loc[i].ra*u.deg, base.loc[i].decl*u.deg, frame='fk5')\n",
    "\n",
    "        c2 = SkyCoord(base.drop(index=i).ra.values*u.deg, \n",
    "                  base.drop(index=i).decl.values*u.deg, frame='fk5')\n",
    "    except IndexError:\n",
    "        print i\n",
    "    if np.min(c1.separation(ateam_coord).deg) < 10:\n",
    "        continue \n",
    "        \n",
    "    elif np.min(c1.separation(aart_coord).deg) < 3 and base.loc[i].f_datapoints.astype(float) > 10:\n",
    "        if len(AART_catsource) == 0:\n",
    "            AART_catsource = pd.DataFrame(base.loc[i]).T\n",
    "        else:\n",
    "            AART_catsource = pd.concat([AART_catsource, pd.DataFrame(base.loc[i]).T])\n",
    " \n",
    "\n",
    "    elif np.logical_or(((c1.separation(c2).deg) > 5),\n",
    "                       (np.abs(base.loc[i].timestep - base.drop(index=i).timestep) > 1000)).all():\n",
    "        if len(filtered) == 0:\n",
    "            filtered = pd.DataFrame(base.loc[i]).T\n",
    "        else:\n",
    "            filtered = pd.concat([filtered, pd.DataFrame(base.loc[i]).T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresh = 5\n",
    "\n",
    "_filtered = filtered\n",
    "\n",
    "\n",
    "pass_list = [] \n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "\n",
    "# plt.plot(base.ra, \n",
    "#          base.decl,\n",
    "#          \".\", label=\"{} Candidates\".format(len(base)))\n",
    "\n",
    "# plt.plot(AART_catsource.ra, \n",
    "#          AART_catsource.decl,\n",
    "#          \".\", label=\"{} Catalogued\".format(len(AART_catsource)))\n",
    "\n",
    "\n",
    "# plt.plot(_filtered.ra,\n",
    "#          _filtered.decl,\n",
    "#          \".\", label=\"{} Pass Filter\".format(len(_filtered)))\n",
    "\n",
    "\n",
    "\n",
    "# plt.scatter(aart.ra,aart.decl,\n",
    "#             edgecolor=\"C1\", facecolor=\"none\",\n",
    "#             s=100, label=\"AARTFAAC catalogue\")\n",
    "\n",
    "\n",
    "# for i in range(len(_filtered)):\n",
    "#     plt.annotate(s=_filtered.index.values[i],\n",
    "#                  xy=(_filtered.ra.values[i],_filtered.decl.values[i]),\n",
    "#                  xycoords=\"data\")\n",
    "#     pass_list.append(_filtered.index.values[i])\n",
    "    \n",
    "# plt.scatter(ateam[\"ra\"],ateam[\"decl\"],\n",
    "#             edgecolor=\"black\", facecolor=\"none\",\n",
    "#             s=500, label=\"Ateam\")\n",
    "\n",
    "# survey_stats.set_value(survey_stats.obs == dbname,\"candidate\", len(base))\n",
    "# survey_stats.set_value(survey_stats.obs == dbname,\"pass\", len(_filtered))\n",
    "# survey_stats.to_csv(\"survey_stats.csv\", index=False)\n",
    "\n",
    "# plt.ylim([0,90])\n",
    "# plt.ylabel(\"Declination [deg]\")\n",
    "# plt.xlabel(\"Right Ascension [deg]\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(ObsDir+dbname+\"_skymap.png\")\n",
    "\n",
    "\n",
    "vlssr_thresh= 5\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Observation: AS\"+dbname)\n",
    "for i in np.arange(-40,80,10):\n",
    "    plt.plot(pol2cart(np.abs(90-i*np.ones(50)),np.deg2rad(np.linspace(0,360,50)))[0],\n",
    "             pol2cart(np.abs(90-i*np.ones(50)),np.deg2rad(np.linspace(0,360,50)))[1],\"--\",lw=0.5,c=\"lightgrey\")\n",
    "    \n",
    "for i in np.arange(0,360,10):\n",
    "    plt.plot(pol2cart(np.abs(90-np.linspace(-40,90,50)),np.deg2rad(i*np.ones(50)))[0],\n",
    "             pol2cart(np.abs(90-np.linspace(-40,90,50)),np.deg2rad(i*np.ones(50)))[1],\"--\",lw=0.5,c=\"lightgrey\") \n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-base[base.det_sigma >= 8].decl),np.deg2rad(base[base.det_sigma >= 8].ra.astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-base[base.det_sigma >= 8].decl),np.deg2rad(base[base.det_sigma >= 8].ra.astype(\"float\")))[1],\n",
    "            lw =0,s=30,c=\"blue\",label=\"{} Candidates\".format(len(base[base.det_sigma >= 8])))\n",
    "\n",
    "# plt.scatter(pol2cart(np.abs(90-base.decl),np.deg2rad(base.ra.astype(\"float\")))[0],\n",
    "#             pol2cart(np.abs(90-base.decl),np.deg2rad(base.ra.astype(\"float\")))[1],\n",
    "#             lw =0,s=30,c=\"blue\",label=\"{} Candidates\".format(len(base)))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-aart[\"decl\"]),np.deg2rad(aart[\"ra\"]))[0],\n",
    "            pol2cart(np.abs(90-aart[\"decl\"]),np.deg2rad(aart[\"ra\"]))[1],\n",
    "            lw =2,s=100,marker=\"o\",edgecolor=\"C1\", facecolor=\"none\",label=\"AARTFAAC catalogue\")\n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-AART_catsource.decl),np.deg2rad(AART_catsource.ra.astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-AART_catsource.decl),np.deg2rad(AART_catsource.ra.astype(\"float\")))[1],\n",
    "            lw =0,s=30,facecolor=\"C1\",label=\"{} Catalogued\".format(len(AART_catsource)))\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-_filtered[\"decl\"]),np.deg2rad(_filtered[\"ra\"].astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-_filtered[\"decl\"]),np.deg2rad(_filtered[\"ra\"].astype(\"float\")))[1],\n",
    "             s=30,c=\"C2\",label=\"{} Pass Filter\".format(len(_filtered)))\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-ateam[\"decl\"]),np.deg2rad(ateam[\"ra\"]))[0],\n",
    "            pol2cart(np.abs(90-ateam[\"decl\"]),np.deg2rad(ateam[\"ra\"]))[1],\n",
    "            edgecolor=\"black\", facecolor=\"none\",s=500, label=\"Ateam\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.scatter(pol2cart(np.abs(90-vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000),\n",
    "#                      np.deg2rad(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000))[0],\n",
    "#             pol2cart(np.abs(90-vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000),\n",
    "#                      np.deg2rad(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000))[1],\n",
    "#             edgecolor=\"black\", facecolor=\"none\",s=50, label=\"VLSSr\")\n",
    "\n",
    "\n",
    "bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.6)\n",
    "\n",
    "\n",
    "vlssr_c = SkyCoord(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000.values*u.deg,\n",
    "              vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000.values*u.deg, frame='fk5')\n",
    "\n",
    "\n",
    "vlssr_assoc_x = [] \n",
    "vlssr_assoc_y = [] \n",
    "\n",
    "for i in range(len(_filtered)):\n",
    "    \n",
    "#     filter_c = SkyCoord(_filtered.iloc[i].ra*u.deg, _filtered.iloc[i].decl*u.deg, frame='fk5')\n",
    "\n",
    "#     if np.min(filter_c.separation(vlssr_c).deg) < 0.5:\n",
    "#         vlssr_assoc_x.append(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[0])\n",
    "#         vlssr_assoc_y.append(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[1])\n",
    "\n",
    "# #         plt.scatter(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[0],\n",
    "# #             pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[1],\n",
    "# #              marker=\"x\",s=100,c=\"C3\", label=\"VLSSr association\")\n",
    "#         continue \n",
    "\n",
    "    plt.annotate(s=\" \"+str(_filtered.index.values[i]),\n",
    "                 xy=(pol2cart(np.abs(90-_filtered[\"decl\"].values[i]),np.deg2rad(_filtered[\"ra\"].astype(\"float\").values[i]))[0],\n",
    "                     pol2cart(np.abs(90-_filtered[\"decl\"].values[i]),np.deg2rad(_filtered[\"ra\"].astype(\"float\").values[i]))[1]),\n",
    "                 xycoords=\"data\", bbox=bbox_props)\n",
    "    pass_list.append(_filtered.index.values[i])\n",
    "\n",
    "survey_stats.set_value(survey_stats.obs == dbname,\"candidate\", len(base))\n",
    "survey_stats.set_value(survey_stats.obs == dbname,\"pass\", len(_filtered))\n",
    "survey_stats.to_csv(\"survey_stats.csv\", index=False)\n",
    "\n",
    "# plt.scatter(vlssr_assoc_x,vlssr_assoc_y,\n",
    "#      marker=\"x\",s=100,c=\"C3\", label=\"VLSSr > {} Jy\".format(vlssr_thresh) )    \n",
    "    \n",
    "\n",
    "# for i in range(len(base)):\n",
    "#     plt.annotate(s=\" \"+str(base.index.values[i]),\n",
    "#                  xy=(pol2cart(np.abs(90-base[\"decl\"].values[i]),np.deg2rad(base[\"ra\"].astype(\"float\").values[i]))[0],\n",
    "#                      pol2cart(np.abs(90-base[\"decl\"].values[i]),np.deg2rad(base[\"ra\"].astype(\"float\").values[i]))[1]),\n",
    "#                  xycoords=\"data\", bbox=bbox_props)\n",
    "# #     pass_list.append(_filtered.index.values[i])\n",
    "\n",
    "plt.annotate(s=\"NCP\",\n",
    "             xy=(0,0),horizontalalignment='center', verticalalignment='center',\n",
    "             xycoords=\"data\")\n",
    "\n",
    "plt.xlim([-90,90])\n",
    "plt.ylim([-90,90])\n",
    "plt.legend(loc=\"lower center\", ncol=2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(ObsDir+dbname+\"_skymap.png\")\n",
    "\n",
    "\n",
    "vlssr_thresh= 5\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Observation: AS\"+dbname)\n",
    "for i in np.arange(-40,80,10):\n",
    "    plt.plot(pol2cart(np.abs(90-i*np.ones(50)),np.deg2rad(np.linspace(0,360,50)))[0],\n",
    "             pol2cart(np.abs(90-i*np.ones(50)),np.deg2rad(np.linspace(0,360,50)))[1],\"--\",lw=0.5,c=\"lightgrey\")\n",
    "    \n",
    "for i in np.arange(0,360,10):\n",
    "    plt.plot(pol2cart(np.abs(90-np.linspace(-40,90,50)),np.deg2rad(i*np.ones(50)))[0],\n",
    "             pol2cart(np.abs(90-np.linspace(-40,90,50)),np.deg2rad(i*np.ones(50)))[1],\"--\",lw=0.5,c=\"lightgrey\") \n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-base[base.det_sigma >= 8].decl),np.deg2rad(base[base.det_sigma >= 8].ra.astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-base[base.det_sigma >= 8].decl),np.deg2rad(base[base.det_sigma >= 8].ra.astype(\"float\")))[1],\n",
    "            lw =0,s=30,c=\"blue\",label=\"{} Candidates\".format(len(base[base.det_sigma >= 8])))\n",
    "\n",
    "# plt.scatter(pol2cart(np.abs(90-base.decl),np.deg2rad(base.ra.astype(\"float\")))[0],\n",
    "#             pol2cart(np.abs(90-base.decl),np.deg2rad(base.ra.astype(\"float\")))[1],\n",
    "#             lw =0,s=30,c=\"blue\",label=\"{} Candidates\".format(len(base)))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-aart[\"decl\"]),np.deg2rad(aart[\"ra\"]))[0],\n",
    "            pol2cart(np.abs(90-aart[\"decl\"]),np.deg2rad(aart[\"ra\"]))[1],\n",
    "            lw =2,s=100,marker=\"o\",edgecolor=\"C1\", facecolor=\"none\",label=\"AARTFAAC catalogue\")\n",
    "\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-AART_catsource.decl),np.deg2rad(AART_catsource.ra.astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-AART_catsource.decl),np.deg2rad(AART_catsource.ra.astype(\"float\")))[1],\n",
    "            lw =0,s=30,facecolor=\"C1\",label=\"{} Catalogued\".format(len(AART_catsource)))\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-_filtered[\"decl\"]),np.deg2rad(_filtered[\"ra\"].astype(\"float\")))[0],\n",
    "            pol2cart(np.abs(90-_filtered[\"decl\"]),np.deg2rad(_filtered[\"ra\"].astype(\"float\")))[1],\n",
    "             s=30,c=\"C2\",label=\"{} Pass Filter\".format(len(_filtered)))\n",
    "\n",
    "plt.scatter(pol2cart(np.abs(90-ateam[\"decl\"]),np.deg2rad(ateam[\"ra\"]))[0],\n",
    "            pol2cart(np.abs(90-ateam[\"decl\"]),np.deg2rad(ateam[\"ra\"]))[1],\n",
    "            edgecolor=\"black\", facecolor=\"none\",s=500, label=\"Ateam\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.scatter(pol2cart(np.abs(90-vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000),\n",
    "#                      np.deg2rad(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000))[0],\n",
    "#             pol2cart(np.abs(90-vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000),\n",
    "#                      np.deg2rad(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000))[1],\n",
    "#             edgecolor=\"black\", facecolor=\"none\",s=50, label=\"VLSSr\")\n",
    "\n",
    "\n",
    "bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.6)\n",
    "\n",
    "\n",
    "vlssr_c = SkyCoord(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000.values*u.deg,\n",
    "              vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000.values*u.deg, frame='fk5')\n",
    "\n",
    "\n",
    "vlssr_assoc_x = [] \n",
    "vlssr_assoc_y = [] \n",
    "\n",
    "for i in range(len(_filtered)):\n",
    "    \n",
    "    filter_c = SkyCoord(_filtered.iloc[i].ra*u.deg, _filtered.iloc[i].decl*u.deg, frame='fk5')\n",
    "\n",
    "    if np.min(filter_c.separation(vlssr_c).deg) < 0.5:\n",
    "        vlssr_assoc_x.append(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[0])\n",
    "        vlssr_assoc_y.append(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[1])\n",
    "\n",
    "#         plt.scatter(pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[0],\n",
    "#             pol2cart(np.abs(90-_filtered.iloc[i][\"decl\"]),np.deg2rad(_filtered.iloc[i][\"ra\"].astype(\"float\")))[1],\n",
    "#              marker=\"x\",s=100,c=\"C3\", label=\"VLSSr association\")\n",
    "        continue \n",
    "\n",
    "    plt.annotate(s=\" \"+str(_filtered.index.values[i]),\n",
    "                 xy=(pol2cart(np.abs(90-_filtered[\"decl\"].values[i]),np.deg2rad(_filtered[\"ra\"].astype(\"float\").values[i]))[0],\n",
    "                     pol2cart(np.abs(90-_filtered[\"decl\"].values[i]),np.deg2rad(_filtered[\"ra\"].astype(\"float\").values[i]))[1]),\n",
    "                 xycoords=\"data\", bbox=bbox_props)\n",
    "    \n",
    "plt.scatter(vlssr_assoc_x,vlssr_assoc_y,\n",
    "     marker=\"x\",s=100,c=\"C3\", label=\"VLSSr > {} Jy\".format(vlssr_thresh) )    \n",
    "    \n",
    "\n",
    "# for i in range(len(base)):\n",
    "#     plt.annotate(s=\" \"+str(base.index.values[i]),\n",
    "#                  xy=(pol2cart(np.abs(90-base[\"decl\"].values[i]),np.deg2rad(base[\"ra\"].astype(\"float\").values[i]))[0],\n",
    "#                      pol2cart(np.abs(90-base[\"decl\"].values[i]),np.deg2rad(base[\"ra\"].astype(\"float\").values[i]))[1]),\n",
    "#                  xycoords=\"data\", bbox=bbox_props)\n",
    "# #     pass_list.append(_filtered.index.values[i])\n",
    "\n",
    "plt.annotate(s=\"NCP\",\n",
    "             xy=(0,0),horizontalalignment='center', verticalalignment='center',\n",
    "             xycoords=\"data\")\n",
    "\n",
    "plt.xlim([-90,90])\n",
    "plt.ylim([-90,90])\n",
    "plt.legend(loc=\"lower center\", ncol=2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(ObsDir+dbname+\"_skymap_vlssrfilter.png\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "# plt.title(dbname+\" scintillation map\")\n",
    "# plt.scatter(AART_catsource.ra.astype(float),AART_catsource.decl.astype(float),\n",
    "#             edgecolor=\"C1\", facecolor=\"none\",\n",
    "#             s=1e4*AART_catsource.eta_int.astype(float)/AART_catsource.f_datapoints.astype(float), label=\"AARTFAAC catalogue\")\n",
    "\n",
    "# plt.plot(_filtered.ra,\n",
    "#          _filtered.decl,\n",
    "#          \".\", label=\"{} Pass Filter\".format(len(_filtered)))\n",
    "\n",
    "# plt.ylim([0,90])\n",
    "# plt.ylabel(\"Declination [deg]\")\n",
    "# plt.xlabel(\"Right Ascension [deg]\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(ObsDir+dbname+\"_scintilationmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ID in pass_list:#AART_catsource.index:\n",
    "\n",
    "    source_df = retrieve_source(data, _ID)\n",
    "\n",
    "\n",
    "    _source_flux = source_df.f_int[(source_df.freq_eff < 60000000) ].values\n",
    "    _index = source_df.extract_type[(source_df.freq_eff < 60000000) ].values\n",
    "    _source_flux[(_index == 1)] = np.nan\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.errorbar(source_df.taustart_ts[(source_df.freq_eff < 60000000)].values,\n",
    "                 _source_flux, \n",
    "                 yerr = source_df.f_int_err[(source_df.freq_eff < 60000000) ].values,\n",
    "                 fmt=\"o-\", color=\"C3\",ecolor=\"C1\", label=\"57.8 MHz, det\")\n",
    "\n",
    "    del _source_flux\n",
    "\n",
    "    if len(source_df.f_int_err[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values) > 0:\n",
    "        plt.errorbar(source_df.taustart_ts[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     source_df.f_int[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values, \n",
    "                     yerr = source_df.f_int_err[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     fmt=\".\", color=\"C3\",ecolor=\"C1\", label=\"57.8 MHz, ff\")\n",
    "\n",
    "\n",
    "    _source_flux = source_df.f_int[(source_df.freq_eff > 60000000) ].values\n",
    "    _index = source_df.extract_type[(source_df.freq_eff > 60000000) ].values\n",
    "    _source_flux[(_index == 1)] = np.nan\n",
    "\n",
    "\n",
    "    plt.errorbar(source_df.taustart_ts[(source_df.freq_eff > 60000000) ].values,\n",
    "                 _source_flux, \n",
    "                 yerr = source_df.f_int_err[(source_df.freq_eff > 60000000) ].values,\n",
    "                 fmt=\"o-\",color=\"C0\", ecolor=\"C1\", label=\"61.3 MHz, det\")\n",
    "\n",
    "    del _source_flux\n",
    "\n",
    "    if len(source_df.f_int_err[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values) > 0:\n",
    "        plt.errorbar(source_df.taustart_ts[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     source_df.f_int[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values, \n",
    "                     yerr = source_df.f_int_err[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     fmt=\".\", color=\"C0\",ecolor=\"C1\", label=\"61.3 MHz, ff\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(str(_ID)+\": ra: \"+str(round(source_df.ra.mean(),2))+\", dec: \"+str(round(source_df.decl.mean(),2)))\n",
    "    plt.ylabel(\"Integrated flux [arbitrary]\")\n",
    "    plt.xlabel(\"Time [UTC]\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ObsDir+str(_ID)+\"_lightcurve.png\")\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "stamp_side = 600\n",
    "half_side = int(stamp_side/2)\n",
    "\n",
    "x = np.linspace(0, stamp_side, stamp_side)\n",
    "y = np.linspace(0, stamp_side, stamp_side)\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "map_dir = \"/home/kuiack/skymaps/\"\n",
    "files = glob.glob(map_dir+\"*.fits\")\n",
    "BANDS = [os.path.basename(i)[:4] for i in files]\n",
    "\n",
    "delta = 100 \n",
    "\n",
    "fig_n = 1\n",
    "\n",
    "map_load_1 = hp.fitsfunc.read_map(map_dir+BANDS[2]+\"_512_map.fits\")\n",
    "map_load_2 = hp.fitsfunc.read_map(map_dir+BANDS[3]+\"_512_map.fits\")\n",
    "\n",
    "for _ID in pass_list: #AART_catsource.index:\n",
    "\n",
    "    source_df = retrieve_source(data, _ID)\n",
    "\n",
    "    _source_flux = source_df.f_int[(source_df.freq_eff < 60000000) ].values\n",
    "    _index = source_df.extract_type[(source_df.freq_eff < 60000000) ].values\n",
    "    _source_flux[(_index == 1)] = np.nan\n",
    "\n",
    "\n",
    "    plt.figure(fig_n,figsize=(12,12))\n",
    "    \n",
    "    stamp = hp.gnomview(map_load_1,  xsize=stamp_side,\n",
    "                        rot=([base.loc[_ID].ra,\n",
    "                              base.loc[_ID].decl]),\n",
    "                        coord=\"C\", return_projected_map=True,fig=fig_n,sub=322,notext=True, title=\"Map: 75 MHz\",cbar=False)\n",
    "\n",
    "    hp.projscatter(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000.values,\n",
    "                vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000.values, lonlat=True,\n",
    "                   marker=\"+\", color=\"white\", coord=\"C\")\n",
    "\n",
    "    hp.projscatter(base.loc[_ID].ra,\n",
    "                   base.loc[_ID].decl,lonlat=True,\n",
    "                   edgecolors=\"red\", facecolor=\"none\", s=1500, coord=\"C\", lw=1)\n",
    "\n",
    "\n",
    "\n",
    "    stamp = hp.gnomview(map_load_2, xsize=stamp_side,\n",
    "                        rot=([base.loc[_ID].ra,\n",
    "                              base.loc[_ID].decl]),\n",
    "                        coord=\"C\", return_projected_map=True, fig=1,sub=321, notext=True, title=\"Map: 37.5 MHz\",cbar=False)\n",
    "\n",
    "\n",
    "    hp.projscatter(vlssr[vlssr.Sp > vlssr_thresh]._RAJ2000.values,\n",
    "                vlssr[vlssr.Sp > vlssr_thresh]._DEJ2000.values, lonlat=True,\n",
    "                   marker=\"+\", color=\"white\", coord=\"C\")\n",
    "\n",
    "    hp.projscatter(base.loc[_ID].ra,\n",
    "                   base.loc[_ID].decl,lonlat=True,\n",
    "                   edgecolors=\"red\", facecolor=\"none\", s=1500, coord=\"C\", lw=1)\n",
    "\n",
    "    plt.subplot(313)\n",
    "\n",
    "    plt.errorbar(source_df.taustart_ts[(source_df.freq_eff < 60000000)].values,\n",
    "                 _source_flux, \n",
    "                 yerr = source_df.f_int_err[(source_df.freq_eff < 60000000) ].values,\n",
    "                 fmt=\"o-\", color=\"C3\",ecolor=\"C1\", label=\"57.8 MHz, det\")\n",
    "\n",
    "    del _source_flux\n",
    "\n",
    "    if len(source_df.f_int_err[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values) > 0:\n",
    "        plt.errorbar(source_df.taustart_ts[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     source_df.f_int[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values, \n",
    "                     yerr = source_df.f_int_err[(source_df.freq_eff < 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     fmt=\".\", color=\"C3\",ecolor=\"C1\", label=\"57.8 MHz, ff\")\n",
    "\n",
    "\n",
    "    _source_flux = source_df.f_int[(source_df.freq_eff > 60000000) ].values\n",
    "    _index = source_df.extract_type[(source_df.freq_eff > 60000000) ].values\n",
    "    _source_flux[(_index == 1)] = np.nan\n",
    "\n",
    "\n",
    "    plt.errorbar(source_df.taustart_ts[(source_df.freq_eff > 60000000) ].values,\n",
    "                 _source_flux, \n",
    "                 yerr = source_df.f_int_err[(source_df.freq_eff > 60000000) ].values,\n",
    "                 fmt=\"o-\",color=\"C0\", ecolor=\"C1\", label=\"61.3 MHz, det\")\n",
    "\n",
    "    del _source_flux\n",
    "\n",
    "    if len(source_df.f_int_err[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values) > 0:\n",
    "        plt.errorbar(source_df.taustart_ts[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     source_df.f_int[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values, \n",
    "                     yerr = source_df.f_int_err[(source_df.freq_eff > 60000000) & (source_df.extract_type == 1 )].values,\n",
    "                     fmt=\".\", color=\"C0\",ecolor=\"C1\", label=\"61.3 MHz, ff\")\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Integrated flux [arbitrary]\")\n",
    "    plt.xlabel(\"Time [UTC]\")\n",
    "\n",
    "    plt.title(\"Obs: AS\"+dbname+\"\\nID: \"+str(_ID)+\", RA \"+str(round(source_df.ra.mean(),2))+\", Dec \"+str(round(source_df.decl.mean(),2)))\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,3,4)\n",
    "    if  os.path.isfile(source_df[ source_df.f_int == source_df.f_int.max()].url[0]):\n",
    "        filename = source_df[ source_df.f_int == source_df.f_int.max()].url[0]\n",
    "    else: \n",
    "        filename = \"/mnt/ais001/\"+source_df[ source_df.f_int == source_df.f_int.max()].url[0].split(\"/\")[2]+\"/\"+source_df[ source_df.f_int == source_df.f_int.max()].url[0].split(\"/\")[3]\n",
    "\n",
    "\n",
    "    wcs = WCS(filename)\n",
    "    im_pix_x, im_pix_y, n, nn = wcs.wcs_world2pix(source_df.ra.mean(),source_df.decl.mean(),1,1,1)\n",
    "\n",
    "    pos = [im_pix_x, im_pix_y]\n",
    "\n",
    "    plt.text(5,92,os.path.basename(filename), color=\"white\", fontsize=12)\n",
    "    plt.text(0.5,0.5,\"max\", color=\"white\", fontsize=18)\n",
    "    plt.imshow(fits.open(filename)[0].data[0,0,pos[1]-delta/2:pos[1]+delta/2,pos[0]-delta/2:pos[0]+delta/2], origin=\"lower\")\n",
    "    plt.scatter(delta/2,delta/2, s=50*delta, facecolor=\"none\", edgecolor=\"red\")\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(3,3,5)\n",
    "    if  os.path.isfile(source_df[ source_df.f_int == source_df.f_int.min()].url[0]):\n",
    "        filename = source_df[ source_df.f_int == source_df.f_int.min()].url[0]\n",
    "\n",
    "    wcs = WCS(filename)\n",
    "    im_pix_x, im_pix_y, n, nn = wcs.wcs_world2pix(source_df.ra.mean(),source_df.decl.mean(),1,1,1)\n",
    "\n",
    "    pos = [im_pix_x, im_pix_y]\n",
    "\n",
    "    plt.text(5,92,os.path.basename(filename), color=\"white\", fontsize=12)\n",
    "    plt.text(0.5,0.5,\"min\", color=\"white\", fontsize=18)\n",
    "    plt.imshow(fits.open(filename)[0].data[0,0,pos[1]-delta/2:pos[1]+delta/2,pos[0]-delta/2:pos[0]+delta/2], origin=\"lower\")\n",
    "    plt.scatter(delta/2,delta/2, s=50*delta, facecolor=\"none\", edgecolor=\"red\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(3,3,6)\n",
    "    plt.plot()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ObsDir+str(_ID)+\"_lightcurve.png\")\n",
    "    fig_n +=1\n",
    "    \n",
    "    if not os.path.exists(ObsDir):\n",
    "        os.makedirs(ObsDir+\"/CandidatePandas\")\n",
    "\n",
    "    for _ID in filtered.index:\n",
    "        source_df = retrieve_source(data, _ID)\n",
    "        source_df.to_csv(ObsDir+\"/CandidatePandas/\"+str(_ID)+\"-source_df.csv\", index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
